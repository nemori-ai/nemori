# Nemori：自然启发的情景记忆系统

🌍 [English](README.md) | 🌍 [中文](README-CN.md) | **📄 [论文](https://arxiv.org/abs/2508.03341)**

## 项目概述  [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/nemori-ai/nemori)

Nemori-AI 旨在让大语言模型具备类人的情景记忆能力。

Nemori 通过自然、事件化的索引方式，帮助系统在关键时刻精准回溯原始经历。

愿景：让每一次数据交互，都能像人类记忆一样被理解、被回忆、被延续。

Nemori 源自我们团队 Tanka.ai 项目中记忆系统的情景记忆索引模块——这是一个我们计划开源的 MVP 实现。其核心目标是分享我们通过自然启发的情景记忆来构建记忆索引（Nemori: Nature-Inspired Episodic Memory）的方法。

虽然 Mem0、Letta、Supermemory、ZEP、MemOS 等先前系统在 AI 记忆方面做出了卓越尝试，在 LoCoMo 基准测试中取得了先进的性能，但 Nemori 引入了一种创新且简约的方法，专注于与人类情景记忆模式保持一致。鉴于最近优秀的开源项目和记忆系统研究的涌现，我们都汇聚在使用 LoCoMo 数据集作为基准，因此我们决定用展示我们情景记忆索引方法的 MVP 实现参与这一基准测试。

## 实验结果

为了突出 Nemori 这个简洁方法的优越性，我们在 LoCoMo 基准测试上进行了评估，与先前的最先进方法进行了比较：

### LoCoMo 基准测试结果

在 LoCoMo（长上下文对话建模）数据集上，Nemori 展现了卓越的性能：

![LoCoMo Benchmark Results](figures/locomo-scores.png)

## 复现方法

要复现 Nemori 在 LoCoMo 基准测试上的实验结果，请参考 [evaluation/README.md](evaluation/README.md) 获取详细的评测环境搭建与运行步骤。

### 简要流程说明（2 条提示词 + BM25 检索）

> Nemori 的 LoCoMo 复现流程极其简单：情景构建阶段只需 **2 条简短提示词**（边界探测 & 情景生成），随后通过 **BM25** 完成检索与回答生成，无需额外的大模型调用。

![Process Flow](figures/flow.png)

1. **情景边界探测 — 提示词** `Detect episode boundaries along natural topic shifts`

2. **情景生成 — 提示词** `Summarize each segment into an episodic memory`

3. **BM25 索引构建 — 无额外 LLM 调用 & 无 Embedding**

4. **检索与回答生成 — 纯 BM25（同样无额外 LLM 调用）**

## 设计理念

当我们人类回忆过去的事件时，我们的脑海中经常闪现相关的图像、动作或声音。我们的大脑通过让我们重新体验当时发生的事情来帮助我们记忆——这种记忆机制被称为情景记忆。

Nemori 的设计灵感来自人类的情景记忆。Nemori 可以自主地将人与人、人与 AI 智能体或 AI 智能体之间的对话重塑为情景片段。与原始对话相比，情景片段具有更连贯的因果关系和时间表达能力。更重要的是，情景片段的表达在某种程度上与我们人类记忆回忆的粒度相一致，这意味着作为人类，我们更可能提出关于情景片段的问题，这些问题在语义上更接近情景片段本身，而不是原始消息。

### 颗粒度与大模型训练分布的对齐

我们设计中的一个关键洞察是，情景记忆颗粒度对齐为大语言模型提供了潜在的优化收益。由于大模型的训练数据集会对齐人类世界的文本分布，所以对齐回忆颗粒度的同时，也在对齐「自然世界中最大概率的事件表述颗粒度」。

这种对齐提供了几个优势：
- **减少分布偏移**：当存储的情景片段与训练语料中的典型事件跨度匹配时，回忆提示更接近预训练分布，提高了 token 预测概率
- **增强检索精度**：存储「人类尺度」事件的记忆索引操作的是语义纠缠较少的单元，提高了检索中的信噪比

## 技术实现方法

### 数据预处理

由于我们的生产系统增量处理原始情景数据，我们重用了主题分割策略。这体现了情景记忆创建的核心哲学："与人类记忆事件情景的粒度保持一致"。虽然我们的方法可能看起来低效且简单，但这反映了我们 MVP 为了清晰展示方法而做出的简化。在生产环境中，我们采用更具成本效益和高效的方法。

对于情景生成，我们选择了最直接的版本来最好地说明我们的方法，仅使用 gpt-4o-mini/gpt-4.1-mini 进行情景记忆提取。

### 检索策略

我们为每个用户的情景记忆建立了最小的 BM25 索引。这可能会引起疑问，但这同样是一种简化。我们的生产系统采用结合稀疏（BM25）和密集（向量检索）方法的混合检索策略，以平衡召回和语义匹配能力，并针对特定业务需求定制不同的重排策略。

在预处理完成后，后续过程相对简单。我们检索前 20 个结果，让 gpt-4o-mini/gpt-4.1-mini 生成响应，并遵循与其他项目几乎相同的评估方法。

## 未来路线图

1. [计划开源] 添加「语义记忆」能力，用于改善情景记忆丢失原文中名称、地点等信息的问题。

2. 仅仅拥有特定事件的情景记忆是不够的。我们希望通过相似性度量等方法自动聚合情景片段，形成更长期和通用的高级情景片段。

## FAQ

### 1. Nemori 在 LoCoMo 数据集的分数看起来跟 MemOS 提升并不大，你们的记忆方案有什么显著的优势吗？

MemOS 是一个非常优秀的方案，并且在我们真实的系统中，有非常多类似模块设计，在实际的落地场景中，记忆还是一个与业务强相关的问题，因此我们并无意对比框架本身的优劣。我们想表达的是，沿着「与人类记忆事件的颗粒度对齐」这一个简单而深刻的洞察作为起点，**在特定类型的任务中**只需要很简单的方法就能媲美复杂的记忆框架。在这个版本中，甚至都没有使用 Embedding 来增强语意相关性的召回效果。因此，如果只是想提升这个数据集的分数，还有非常大的提升空间。大家感兴趣可以自行尝试引入一些常规的优化方案，比如情景切割后的边界上下文修复，策略性的带入部分原文，引入混合召回+Rerank，或者进行记忆关联融合等，这些都是我们在真实系统中使用并且被证明有效的方法。

### 2. 为什么检索之后只用情景，不考虑带上原文？

因为我们真实的系统中，有另一套方案来解决「某些信息仅能在原文获取」的问题（后续计划开源），大概的方式就是会有选择性的 fusion 关键性语义记忆回情景记忆，在这里我们简化掉了。同时我们不觉得直接带全部原文或者带 top-x 个原文，会有特别明显的提升。直觉上个别 case 可能可以答对，但是整体上变化不会太大（这里主要受限于 gpt-4o-mini），感兴趣的可以试一下。

### 3. Nemori 的实验数据中，每个问题消耗的 token 明显超过了其他方法，所以这个效果是靠大量的上下文换来的吗？

情景记忆的构建策略，会让情景表述比一般的总结性语句长，在同样取 topk = 20 的条件下，总 token 数要比其他方法高不少，但根据我们的经验，即使 topk = 10（即 token ≈ 减半），可能表现差别不会太大。反过来，如果在一个合理范围内提升窗口上下文的使用对性能有提升，为什么不呢？

### 4. 该方法中关于情景的表述，有大量的类似「the previous Friday (June 23, 2023)」这样的表述，是面向评估集的定向优化吗？

在我们团队真实的 Agent 系统中，有专门的时间增强处理过程，并将结果挂载在情景的元数据中，帮助在不同场景的业务中准确找到相对/绝对时间。我们在 MVP 实现做了简化，直接使用这样的形式拼接在情景正文中。而如果这一个操作如果对 LoCoMo 数据集有帮助（其实我并不太确定，因为第一版就是这么做的），那么说明这个数据集的构造方式，与我们真实的业务场景比较接近，也是非常符合预期的。

### 5. 在代码中，有很多看起来不知道用在哪里的处理，比如 EpisodeLevel、Time Gap 的计算等，为什么在一个 MVP 项目里面会设计这些元素？

50% 是生产项目迁移时的一些功能没被仔细剥离，50% 是 Claude Code 自由发挥。

### 6. 情景记忆这个方法有在其他场景证明有效性吗？

我们的本意，就是在「AI Agent 作为用户社交/办公的助理」和「通用 ChatBot」两个场景下，设计一种更高效的「记忆索引方式」。所以虽然我们没做过太多实验，但是基本可以推断出来，这个方法拿去做文档场景、知识库场景的记忆，应该是不会有什么直接提升的。

## 特别感谢

MemOS 团队——我们从他们的项目中分叉并扩展了评估框架以支持 Nemori 基准测试。

## 开源协议

本项目采用 MIT 许可证 - 详见 [LICENSE](LICENSE) 文件。

**Nemori** - 赋予 AI 智能体长期记忆以驱动其自我进化 🚀