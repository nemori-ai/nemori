"""
Enhanced Semantic Memory Demo with Real Embedding Search

This script demonstrates the complete semantic memory system with real
embedding-based similarity search using OpenAI embeddings.
"""

import asyncio
import os
from datetime import datetime
from pathlib import Path

from nemori.core.data_types import SemanticNode, SemanticRelationship, RelationshipType
from nemori.storage.storage_types import StorageConfig, SemanticNodeQuery, SortOrder
from nemori.storage.duckdb_semantic_storage import DuckDBSemanticMemoryRepository


async def main():
    print("ğŸ§  Nemori Enhanced Semantic Memory System - Embedding Demo")
    print("=" * 65)
    api_key = "sk-NuO4dbNTkXXi5zWYkLFnhyug1kkqjeysvrb74pA9jTGfz8cm"
    base_url = "https://jeniya.cn/v1"
    # Check for OpenAI API key
    openai_key = "sk-NuO4dbNTkXXi5zWYkLFnhyug1kkqjeysvrb74pA9jTGfz8cm"
    openai_base_url = "https://jeniya.cn/v1"
    #     openai_key = "EMPTY"
    # openai_base_url = "http://localhost:6007/v1"
    # model = "qwen3-emb"
    if not openai_key and not openai_base_url:
        print("âš ï¸  Warning: No OPENAI_API_KEY or OPENAI_BASE_URL found in environment.")
        print("   Embedding-based similarity search will fallback to text search.")
        print("   Set OPENAI_API_KEY or OPENAI_BASE_URL to test real embeddings.\n")

    # Initialize semantic storage with embedding configuration
    print("\nğŸ”§ Initializing semantic memory storage with embedding support...")
    
    storage_config = StorageConfig(
        connection_string="enhanced_semantic_demo.duckdb", 
        backend_type="duckdb"
    )
    # Add embedding configuration
    storage_config.openai_api_key = openai_key
    storage_config.openai_base_url = openai_base_url

    semantic_storage = DuckDBSemanticMemoryRepository(storage_config)
    await semantic_storage.initialize()
    print("âœ… Enhanced semantic memory storage initialized")

    try:
        # Demo 1: Create semantic nodes with embeddings
        print("\nğŸ“ Demo 1: Creating semantic knowledge with embeddings")
        print("-" * 55)

        # Create comprehensive semantic nodes
        nodes_data = [
            {
                "key": "ç ”ç©¶é¢†åŸŸ",
                "value": "äººå·¥æ™ºèƒ½ä¸æœºå™¨å­¦ä¹ ",
                "context": "Johnä¸“æ³¨äºäººå·¥æ™ºèƒ½é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯æœºå™¨å­¦ä¹ ç®—æ³•çš„ç ”ç©¶å’Œåº”ç”¨",
                "confidence": 0.95
            },
            {
                "key": "ç¼–ç¨‹è¯­è¨€åå¥½", 
                "value": "Pythonå’ŒJavaScript",
                "context": "Johnåœ¨å¼€å‘ä¸­ä¸»è¦ä½¿ç”¨Pythonè¿›è¡ŒAIç ”ç©¶ï¼ŒJavaScriptç”¨äºå‰ç«¯å¼€å‘",
                "confidence": 0.9
            },
            {
                "key": "æŠ€æœ¯æ ˆ",
                "value": "TensorFlowã€PyTorchã€React",
                "context": "Johnç†Ÿç»ƒä½¿ç”¨TensorFlowå’ŒPyTorchè¿›è¡Œæ·±åº¦å­¦ä¹ ï¼ŒReactç”¨äºæ„å»ºç”¨æˆ·ç•Œé¢",
                "confidence": 0.85
            },
            {
                "key": "å·¥ä½œç»éªŒ",
                "value": "5å¹´è½¯ä»¶å¼€å‘ï¼Œ3å¹´AIç ”ç©¶",
                "context": "Johnæœ‰5å¹´çš„è½¯ä»¶å¼€å‘ç»éªŒï¼Œæœ€è¿‘3å¹´ä¸“æ³¨äºAIå’Œæœºå™¨å­¦ä¹ ç ”ç©¶",
                "confidence": 0.9
            },
            {
                "key": "æ•™è‚²èƒŒæ™¯",
                "value": "è®¡ç®—æœºç§‘å­¦ç¡•å£«å­¦ä½",
                "context": "Johnæ‹¥æœ‰è®¡ç®—æœºç§‘å­¦ç¡•å£«å­¦ä½ï¼Œä¸“ä¸šæ–¹å‘ä¸ºäººå·¥æ™ºèƒ½",
                "confidence": 0.95
            }
        ]

        nodes = []
        for i, node_data in enumerate(nodes_data):
            node = SemanticNode(
                owner_id="john",
                key=node_data["key"],
                value=node_data["value"],
                context=node_data["context"],
                confidence=node_data["confidence"],
                discovery_episode_id=f"episode_{i+1}",
                linked_episode_ids=[f"episode_{i+1}"],
            )
            
            # Store node with embedding generation
            embedding_content = f"{node.key}: {node.value}. {node.context}"
            await semantic_storage.store_semantic_node_with_embedding(node, embedding_content)
            nodes.append(node)
            print(f"ğŸ’¾ Stored with embedding: {node.key} -> {node.value}")

        # Demo 2: Create relationships
        print("\nğŸ”— Demo 2: Creating semantic relationships")
        print("-" * 45)

        # Create meaningful relationships between nodes
        relationships_data = [
            (0, 2, RelationshipType.RELATED, "æŠ€æœ¯æ ˆæ”¯æŒç ”ç©¶é¢†åŸŸ"),
            (1, 2, RelationshipType.PART_OF, "ç¼–ç¨‹è¯­è¨€æ˜¯æŠ€æœ¯æ ˆçš„ä¸€éƒ¨åˆ†"),
            (3, 0, RelationshipType.RELATED, "å·¥ä½œç»éªŒä¸ç ”ç©¶é¢†åŸŸç›¸å…³"),
            (4, 0, RelationshipType.RELATED, "æ•™è‚²èƒŒæ™¯æ”¯æ’‘ç ”ç©¶é¢†åŸŸ")
        ]

        for source_idx, target_idx, rel_type, description in relationships_data:
            relationship = SemanticRelationship(
                source_node_id=nodes[source_idx].node_id,
                target_node_id=nodes[target_idx].node_id,
                relationship_type=rel_type,
                strength=0.8,
                description=description,
                discovery_episode_id="relationship_discovery"
            )
            await semantic_storage.store_semantic_relationship(relationship)
            print(f"ğŸ”— Created: {nodes[source_idx].key} <-> {nodes[target_idx].key}")

        # Demo 3: Text-based search
        print("\nğŸ” Demo 3: Traditional text-based search")
        print("-" * 45)

        text_query = SemanticNodeQuery(
            owner_id="john", 
            text_search="ç¼–ç¨‹", 
            limit=10, 
            sort_by="confidence", 
            sort_order=SortOrder.DESC
        )
        text_results = await semantic_storage.search_semantic_nodes(text_query)
        print(f"ğŸ“Š Text search for 'ç¼–ç¨‹' found {len(text_results.semantic_nodes)} results:")
        for node in text_results.semantic_nodes:
            print(f"  â€¢ {node.key}: {node.value} (confidence: {node.confidence:.2f})")

        # Demo 4: Embedding-based similarity search
        print("\nğŸ¯ Demo 4: Embedding-based similarity search")
        print("-" * 50)

        # Test various similarity queries
        similarity_queries = [
            "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯",
            "è½¯ä»¶å¼€å‘å·¥å…·å’Œæ¡†æ¶", 
            "å­¦å†å’Œæ•™è‚²ç»å†",
            "JavaScriptå‰ç«¯å¼€å‘",
            "äººå·¥æ™ºèƒ½ç ”ç©¶ç»éªŒ"
        ]

        for query in similarity_queries:
            print(f"\nğŸ” Similarity search for: '{query}'")
            similar_nodes = await semantic_storage.similarity_search_semantic_nodes("john", query, limit=3)
            
            if similar_nodes:
                print(f"   Found {len(similar_nodes)} similar nodes:")
                for node in similar_nodes:
                    print(f"   ğŸ¯ {node.key}: {node.value}")
            else:
                print("   No similar nodes found (likely no embeddings available)")

        # Demo 5: Knowledge evolution with embeddings
        print("\nğŸ”„ Demo 5: Knowledge evolution with embedding updates")
        print("-" * 55)

        # Evolve research focus
        research_node = next(node for node in nodes if node.key == "ç ”ç©¶é¢†åŸŸ")
        evolved_node = research_node.evolve(
            new_value="å¤§è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€AI",
            new_context="Johnçš„ç ”ç©¶é‡ç‚¹è½¬å‘å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œå¤šæ¨¡æ€äººå·¥æ™ºèƒ½ç³»ç»Ÿ",
            evolution_episode_id="evolution_episode_1"
        )

        # Update with new embedding (don't store as new, just update)
        new_embedding_content = f"{evolved_node.key}: {evolved_node.value}. {evolved_node.context}"
        
        # Generate new embedding for the evolved content
        if semantic_storage.openai_client:
            try:
                new_embedding = await semantic_storage._generate_query_embedding(new_embedding_content)
                if new_embedding:
                    from dataclasses import replace
                    evolved_node = replace(evolved_node, embedding_vector=new_embedding)
            except Exception as e:
                print(f"Warning: Could not generate new embedding: {e}")
        
        await semantic_storage.update_semantic_node(evolved_node)
        
        print(f"ğŸ”„ Evolved: {evolved_node.key}")
        print(f"  New value: {evolved_node.value}")
        print(f"  Version: {evolved_node.version}")
        print(f"  History: {evolved_node.evolution_history}")

        # Demo 6: Compare similarity before and after evolution
        print("\nğŸ“Š Demo 6: Similarity comparison after evolution")
        print("-" * 50)

        evolution_queries = [
            "å¤§è¯­è¨€æ¨¡å‹GPT",
            "å¤šæ¨¡æ€äººå·¥æ™ºèƒ½",
            "ä¼ ç»Ÿæœºå™¨å­¦ä¹ ç®—æ³•"
        ]

        for query in evolution_queries:
            print(f"\nğŸ” Testing similarity with: '{query}'")
            results = await semantic_storage.similarity_search_semantic_nodes("john", query, limit=2)
            for node in results:
                version_info = f"(v{node.version})" if node.version > 1 else ""
                print(f"   ğŸ¯ {node.key}: {node.value} {version_info}")

        # Demo 7: Comprehensive statistics
        print("\nğŸ“Š Demo 7: Enhanced semantic memory statistics")
        print("-" * 50)

        stats = await semantic_storage.get_semantic_statistics("john")
        print(f"ğŸ“ˆ Comprehensive statistics for 'john':")
        print(f"  â€¢ Total nodes: {stats['node_count']}")
        print(f"  â€¢ Total relationships: {stats['relationship_count']}")
        print(f"  â€¢ Average confidence: {stats['average_confidence']:.2f}")
        print(f"  â€¢ Version distribution: {stats['version_distribution']}")

        # Check embedding availability
        all_nodes = await semantic_storage.get_all_semantic_nodes_for_owner("john")
        nodes_with_embeddings = sum(1 for node in all_nodes if node.embedding_vector)
        print(f"  â€¢ Nodes with embeddings: {nodes_with_embeddings}/{len(all_nodes)}")

        print("\nğŸ‰ Enhanced demo completed successfully!")
        print("\n" + "=" * 65)
        print("âœ¨ Enhanced Features Demonstrated:")
        print("  âœ“ Real embedding generation with OpenAI API")
        print("  âœ“ Vector-based semantic similarity search")
        print("  âœ“ Embedding-aware knowledge storage")
        print("  âœ“ Evolution with embedding updates")
        print("  âœ“ Fallback to text search when embeddings unavailable")
        print("  âœ“ Comprehensive relationship mapping")
        print("  âœ“ Advanced similarity comparisons")

    except Exception as e:
        print(f"âŒ Error during demo: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        # Cleanup
        await semantic_storage.close()

        # Remove demo database
        db_path = Path("enhanced_semantic_demo.duckdb")
        if db_path.exists():
            db_path.unlink()
            print("\nğŸ§¹ Demo database cleaned up")


if __name__ == "__main__":
    asyncio.run(main())