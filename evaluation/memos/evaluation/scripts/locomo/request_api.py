import requests
import json
import time
import os

# --- é…ç½®ä¿¡æ¯ ---
BASE_URL = "http://localhost:5001"

# æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å¯¹è¯ä½œä¸ºä¾‹å­
# æ³¨æ„ï¼šè¿™æ˜¯ä¸ªåŒ…å«ä¸€ä¸ªå¯¹è¯çš„åˆ—è¡¨
conversation_to_update = [
    {
        "sample_id": "test_001",
        "user_id": "77777",
        "conversation": {
            "speaker_a": "å¼ ä¸‰",
            "speaker_b": "æå››",
            "session_1": [
                {
                    "speaker": "å¼ ä¸‰",
                    "dia_id": "D1:1", 
                    "text": "æœ€è¿‘æˆ‘åœ¨å­¦ä¹ Pythonæœºå™¨å­¦ä¹ ï¼Œä½ è§‰å¾—å“ªäº›åº“æ¯”è¾ƒé‡è¦ï¼Ÿ",
                    "timestamp": "2024-01-20T10:00:00Z"
                },
                {
                    "speaker": "æå››",
                    "dia_id": "D1:2",
                    "text": "scikit-learnæ˜¯å…¥é—¨å¿…å¤‡ï¼Œpandasç”¨äºæ•°æ®å¤„ç†ï¼Œnumpyå¤„ç†æ•°å€¼è®¡ç®—ã€‚æ·±åº¦å­¦ä¹ æ¨èPyTorchã€‚",
                    "timestamp": "2024-01-20T10:02:00Z"
                },
                {
                    "speaker": "å¼ ä¸‰", 
                    "dia_id": "D1:3",
                    "text": "PyTorchå’ŒTensorFlowæ¯”è¾ƒï¼Œå“ªä¸ªæ›´é€‚åˆåˆå­¦è€…ï¼Ÿ",
                    "timestamp": "2024-01-20T10:04:00Z"
                },
                {
                    "speaker": "æå››",
                    "dia_id": "D1:4", 
                    "text": "PyTorchçš„åŠ¨æ€å›¾æ›´ç›´è§‚ï¼Œè°ƒè¯•å®¹æ˜“ã€‚TensorFlowé€‚åˆç”Ÿäº§éƒ¨ç½²ï¼Œä½†å­¦ä¹ æ›²çº¿é™¡å³­ã€‚",
                    "timestamp": "2024-01-20T10:06:00Z"
                }
            ],
            "session_1_date_time": "10:00 AM on 20 January, 2024",
            "session_2": [
                {
                    "speaker": "å¼ ä¸‰",
                    "dia_id": "D2:1",
                    "text": "æ•°æ®é¢„å¤„ç†æ–¹é¢æœ‰ä»€ä¹ˆå»ºè®®å—ï¼Ÿæˆ‘çš„æ•°æ®é›†æœ‰å¾ˆå¤šç¼ºå¤±å€¼ã€‚",
                    "timestamp": "2024-01-20T14:00:00Z"
                },
                {
                    "speaker": "æå››", 
                    "dia_id": "D2:2",
                    "text": "ç¼ºå¤±å€¼å¯ä»¥ç”¨å‡å€¼å¡«å……ã€å‰å‘å¡«å……ï¼Œæˆ–è€…ç›´æ¥åˆ é™¤ã€‚è¦çœ‹å…·ä½“ä¸šåŠ¡åœºæ™¯ï¼Œæ—¶é—´åºåˆ—æ•°æ®å»ºè®®å‰å‘å¡«å……ã€‚",
                    "timestamp": "2024-01-20T14:02:00Z"
                }
            ],
            "session_2_date_time": "2:00 PM on 20 January, 2024"
        },
        "qa": [
            {
                "question": "å¼ ä¸‰åœ¨å­¦ä¹ ä»€ä¹ˆæŠ€æœ¯ï¼Ÿ",
                "answer": "Pythonæœºå™¨å­¦ä¹ ", 
                "evidence": ["D1:1"],
                "category": 1
            },
            {
                "question": "æå››æ¨èäº†å“ªäº›Pythonåº“ï¼Ÿ",
                "answer": "scikit-learn, pandas, numpy, PyTorch",
                "evidence": ["D1:2"],
                "category": 1
            }
        ]
    },
]

# ä»å¯¹è¯æ•°æ®ä¸­æå–å…³é”®ä¿¡æ¯
# APIä¸­çš„å¾ˆå¤šæ“ä½œæ˜¯é’ˆå¯¹å•ä¸ªå¯¹è¯çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬å–åˆ—è¡¨çš„ç¬¬ä¸€ä¸ªå…ƒç´ 
single_conversation_data = conversation_to_update[0]
USER_ID = single_conversation_data["user_id"]
SPEAKER_A = single_conversation_data["conversation"]["speaker_a"]
SPEAKER_B = single_conversation_data["conversation"]["speaker_b"]
# ä½¿ç”¨ User ID æ¥åˆ›å»ºä¸€ä¸ªå”¯ä¸€çš„ version
VERSION = f"session_for_user_{USER_ID}"

# åˆå§‹åŒ–æ‰€éœ€çš„é…ç½®ï¼ˆä¸æœåŠ¡å™¨ç«¯ä»£ç ä¿æŒä¸€è‡´ï¼‰
# ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
LLM_CONFIG = {
    "api_key": os.getenv("JENIYA_API_KEY", "sk-NuO4dbNTkXXi5zWYkLFnhyug1kkqjeysvrb74pA9jTGfz8cm"),
    "base_url": os.getenv("JENIYA_BASE_URL", "https://jeniya.cn/v1"),
    "model": "gpt-4o-mini"
}
EMBED_CONFIG = {
    "emb_api_key": "EMPTY",
    "emb_base_url": os.getenv("EMBEDDING_BASE_URL", "http://localhost:6007/v1"),
    "embed_model": "qwen3-emb"
}


def print_response(name, response):
    """æ ¼å¼åŒ–æ‰“å°å“åº”çš„è¾…åŠ©å‡½æ•°"""
    print(f"--- Response from {name} ---")
    print(f"Status Code: {response.status_code}")
    # ä½¿ç”¨ json.dumps ç¾åŒ–è¾“å‡º
    print(json.dumps(response.json(), indent=4, ensure_ascii=False))
    print("-" * 30 + "\n")


def main():
    """ä¸»æ‰§è¡Œå‡½æ•°ï¼ŒæŒ‰é¡ºåºè°ƒç”¨ API"""
    
    # ----------------------------------------------------
    # æ­¥éª¤ 1: åˆå§‹åŒ– Experiment å’Œ Client
    # ----------------------------------------------------
    print(f"ğŸš€ STEP 1: Initializing services for version: {VERSION}\n")

    # åˆå§‹åŒ– Experiment
    exp_payload = {
        "version": VERSION,
        "llm_config": LLM_CONFIG,
        "embed_config": EMBED_CONFIG
    }

    response = requests.post(f"{BASE_URL}/api/initialize/experiment", json=exp_payload)
    response.raise_for_status() # å¦‚æœçŠ¶æ€ç ä¸æ˜¯ 2xxï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
    print_response("Initialize Experiment", response)

    # åˆå§‹åŒ– Client
    client_payload = {
        "version": VERSION,
        "embed_config": EMBED_CONFIG
    }
    response = requests.post(f"{BASE_URL}/api/initialize/client", json=client_payload)
    response.raise_for_status()
    print_response("Initialize Client", response)
    
    # ----------------------------------------------------
    # æ­¥éª¤ 2: æ£€æµ‹å¯¹è¯è¾¹ç•Œ
    # ----------------------------------------------------
    print("ğŸš€ STEP 2: Detecting conversation boundaries...\n")
    boundaries_payload = {
        "version": VERSION,
        # æ³¨æ„ï¼šæ­¤æ¥å£å¤„ç†å•ä¸ªå¯¹è¯ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼ å…¥ `single_conversation_data`
        "messages": single_conversation_data
    }
    boundaries = None
    response = requests.post(f"{BASE_URL}/api/boundaries/detect", json=boundaries_payload)
    response.raise_for_status()
    print_response("Detect Boundaries", response)
    boundaries = response.json().get("episode_boundaries")
    if not boundaries:
        print("âš ï¸ Warning: Did not receive boundaries from the API.")

    # ----------------------------------------------------
    # æ­¥éª¤ 3: ä½¿ç”¨ V2 æ¥å£æ›´æ–°è®°å¿†
    # ----------------------------------------------------
    if boundaries:
        print("ğŸš€ STEP 3: Updating memory using V2 endpoint with detected boundaries...\n")
        update_v2_payload = {
            "version": VERSION,
            "messages": single_conversation_data,
            "boundaries": boundaries
        }
        response = requests.post(f"{BASE_URL}/api/memory/update-v2", json=update_v2_payload)
        response.raise_for_status()
        print_response("Update Memory V2", response)
    
    # --- ï¼ˆå¯é€‰ï¼‰ä½¿ç”¨ä¼ ç»Ÿçš„ /api/memory/update æ¥å£ ---
    # print("ğŸš€ (Optional) STEP 3.A: Updating memory using the standard endpoint...")
    # update_payload = {
    #     "version": VERSION,
    #     "conversations": conversation_to_update # æ­¤æ¥å£éœ€è¦ä¸€ä¸ªå¯¹è¯åˆ—è¡¨
    # }
    # try:
    #     response = requests.post(f"{BASE_URL}/api/memory/update", json=update_payload)
    #     response.raise_for_status()
    #     print_response("Update Memory (Standard)", response)
    #     # æ³¨æ„: è¿™ä¸ªæ¥å£æ˜¯å¼‚æ­¥çš„ (è¿”å› 202)ï¼Œç«‹å³æŸ¥è¯¢å¯èƒ½æŸ¥ä¸åˆ°æœ€æ–°æ•°æ®
    #     # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨å¯èƒ½éœ€è¦ä¸€ä¸ªå›è°ƒæˆ–è½®è¯¢æœºåˆ¶æ¥ç¡®è®¤ä»»åŠ¡å®Œæˆ
    #     print("Waiting 5 seconds for the async update to process...")
    #     time.sleep(5)
    # except requests.exceptions.RequestException as e:
    #     print(f"âŒ Error updating memory (Standard): {e}")
    #     return


    # ----------------------------------------------------
    # æ­¥éª¤ 4: æŸ¥è¯¢è®°å¿†åº“
    # ----------------------------------------------------
    print("ğŸš€ STEP 4: Querying memory...\n")
    query_payload = {
        "version": VERSION,
        "user_id": USER_ID,
        "query": "æå››æ¨èäº†å“ªäº›ç”¨äºæœºå™¨å­¦ä¹ çš„Pythonåº“ï¼Ÿ",
        "speaker_a": SPEAKER_A,
        "speaker_b": SPEAKER_B,
        "top_k": 20
    }
    response = requests.post(f"{BASE_URL}/api/memory/query", json=query_payload)
    response.raise_for_status()
    print_response("Query Memory", response)



if __name__ == "__main__":
    main()