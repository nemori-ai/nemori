"""
Enhanced Semantic Memory Demo for Nemori Framework

This demo showcases the semantic memory functionality integrated with episodic memory,
using a proper end-to-end workflow similar to the evaluation system.
"""

import asyncio
from datetime import datetime
from pathlib import Path

from nemori.core.data_types import ConversationData, DataType, RawEventData, TemporalInfo, SemanticNode
from nemori.core.episode import Episode, EpisodeType, EpisodeLevel
from nemori.storage.storage_types import StorageConfig
from nemori.storage.duckdb_storage import DuckDBSemanticMemoryRepository, DuckDBEpisodicMemoryRepository
from nemori.semantic.discovery import ContextAwareSemanticDiscoveryEngine
from nemori.semantic.evolution import SemanticEvolutionManager
from nemori.semantic.unified_retrieval import UnifiedRetrievalService
from nemori.builders.enhanced_conversation_builder import EnhancedConversationEpisodeBuilder
from nemori.llm.providers.openai_provider import OpenAIProvider

experiment = NemoriExperiment(version=version, episode_mode="speaker", retrievalstrategy=RetrievalStrategy.EMBEDDING)


async def create_demo_conversation():
    """Create demo conversation data in Nemori format."""
    # Create conversation messages
    messages = [
        {
            "speaker_id": "john_conv1",
            "user_name": "John",
            "content": "æˆ‘æœ€è¿‘åœ¨ç ”ç©¶AI Agentçš„è¡Œä¸ºè§„åˆ’",
            "timestamp": "2024-01-15T10:01:00",
            "metadata": {},
        },
        {
            "speaker_id": "user_conv1",
            "user_name": "User",
            "content": "è¿™ä¸ªæ–¹å‘å¾ˆæœ‰å‰æ™¯",
            "timestamp": "2024-01-15T10:02:00",
            "metadata": {},
        },
        {
            "speaker_id": "john_conv1",
            "user_name": "John",
            "content": "æ˜¯çš„ï¼Œç‰¹åˆ«æ˜¯å†³ç­–æœºåˆ¶è¿™å—å¾ˆæœ‰æŒ‘æˆ˜æ€§",
            "timestamp": "2024-01-15T10:03:00",
            "metadata": {},
        },
    ]

    # Create RawEventData
    raw_data = RawEventData(
        data_type=DataType.CONVERSATION,
        content=messages,
        source="demo_conversation",
        temporal_info=TemporalInfo(
            timestamp=datetime.fromisoformat("2024-01-15T10:01:00"), duration=120.0, timezone="UTC"  # 2 minutes
        ),
        metadata={"conversation_id": "conv1", "participant_count": 2},
    )

    return raw_data


async def test_end_to_end_semantic_memory():
    """Test end-to-end semantic memory workflow with episodic integration."""
    print("ğŸš€ End-to-End è¯­ä¹‰è®°å¿†æ¼”ç¤º | Semantic Memory Demo")
    print("=" * 60)

    # Setup storage
    print("\nğŸ”§ åˆå§‹åŒ–å­˜å‚¨ | Initialize Storage...")
    db_dir = Path("demo_storage")
    db_dir.mkdir(exist_ok=True)

    # Clean up existing database
    db_path = db_dir / "semantic_demo.duckdb"
    if db_path.exists():
        db_path.unlink()
        print("ğŸ§¹ Cleaned existing database")

    # Initialize storage
    storage_config = StorageConfig(
        backend_type="duckdb",
        connection_string=str(db_path),
        batch_size=100,
        cache_size=1000,
        enable_semantic_search=True,
    )

    episodic_repo = DuckDBEpisodicMemoryRepository(storage_config)
    semantic_repo = DuckDBSemanticMemoryRepository(storage_config)

    await episodic_repo.initialize()
    await semantic_repo.initialize()

    print("âœ… å­˜å‚¨åˆå§‹åŒ–å®Œæˆ | Storage initialized")

    # Setup LLM provider
    print("\nğŸ¤– åˆå§‹åŒ–LLMæä¾›è€… | Initialize LLM Provider...")
    mock_llm = MockLLMProvider()
    print("âœ… Mock LLM provider initialized")

    # Setup semantic components
    print("\nğŸ§  åˆå§‹åŒ–è¯­ä¹‰ç»„ä»¶ | Initialize Semantic Components...")
    discovery_engine = ContextAwareSemanticDiscoveryEngine(mock_llm)
    evolution_manager = SemanticEvolutionManager(semantic_repo, discovery_engine)
    unified_retrieval = UnifiedRetrievalService(episodic_repo, semantic_repo)

    # Enhanced episode builder
    enhanced_builder = EnhancedConversationEpisodeBuilder(llm_provider=mock_llm, semantic_manager=evolution_manager)

    print("âœ… è¯­ä¹‰ç»„ä»¶åˆå§‹åŒ–å®Œæˆ | Semantic components initialized")

    try:
        # Create demo conversation
        print("\nğŸ“ åˆ›å»ºæ¼”ç¤ºå¯¹è¯ | Create Demo Conversation...")
        raw_data = await create_demo_conversation()
        conversation_data = ConversationData(raw_data)

        print(f"âœ… å¯¹è¯åˆ›å»ºå®Œæˆ: {len(conversation_data.messages)} æ¡æ¶ˆæ¯")
        print(f"   å‚ä¸è€…: {[msg.user_name for msg in conversation_data.messages]}")

        # Build episode with semantic processing
        print("\nğŸ—ï¸ æ„å»ºæƒ…æ™¯è®°å¿† | Build Episodic Memory...")
        episode = await enhanced_builder.build_episode(conversation_data, "john_conv1")

        print(f"âœ… æƒ…æ™¯è®°å¿†æ„å»ºå®Œæˆ:")
        print(f"   æ ‡é¢˜: {episode.title}")
        print(f"   å†…å®¹: {episode.content[:100]}...")
        print(f"   å‘ç°çš„è¯­ä¹‰çŸ¥è¯†æ•°é‡: {episode.metadata.custom_fields.get('discovered_semantics', 0)}")

        # Test semantic retrieval
        print("\nğŸ” æµ‹è¯•è¯­ä¹‰æ£€ç´¢ | Test Semantic Retrieval...")
        semantic_results = await unified_retrieval.search_semantic_memories(
            owner_id="john_conv1", query="ç ”ç©¶", limit=5
        )

        print(f"âœ… è¯­ä¹‰æ£€ç´¢ç»“æœ: {len(semantic_results)} ä¸ªèŠ‚ç‚¹")
        for i, node in enumerate(semantic_results[:3]):
            print(f"   {i+1}. {node.key}: {node.value}")
            print(f"      ç½®ä¿¡åº¦: {node.confidence}")

        # Test episodic retrieval
        print("\nğŸ“š æµ‹è¯•æƒ…æ™¯æ£€ç´¢ | Test Episodic Retrieval...")
        episodic_results = await unified_retrieval.search_episodic_memories(
            owner_id="john_conv1", query="Agent", limit=3
        )

        print(f"âœ… æƒ…æ™¯æ£€ç´¢ç»“æœ: {len(episodic_results)} ä¸ªæƒ…æ™¯")
        for i, ep in enumerate(episodic_results):
            print(f"   {i+1}. {ep.title}")
            print(f"      å†…å®¹é¢„è§ˆ: {ep.content[:50]}...")

        # Test knowledge evolution
        print("\nğŸ”„ æµ‹è¯•çŸ¥è¯†æ¼”å˜ | Test Knowledge Evolution...")
        await test_knowledge_evolution(enhanced_builder, unified_retrieval)

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼| All tests passed!")
        print("è¯­ä¹‰è®°å¿†ç³»ç»Ÿä¸æƒ…æ™¯è®°å¿†å®Œå…¨é›†æˆ | Semantic memory fully integrated with episodic memory")

    finally:
        await episodic_repo.close()
        await semantic_repo.close()


async def test_knowledge_evolution(builder, unified_retrieval):
    """Test knowledge evolution with a follow-up conversation."""
    print("\n   ğŸ“ åˆ›å»ºæ¼”å˜å¯¹è¯...")

    # Create follow-up conversation showing evolution
    messages = [
        {
            "speaker_id": "john_conv2",
            "user_name": "John",
            "content": "æˆ‘ç°åœ¨ä¸åªç ”ç©¶AI Agentè¡Œä¸ºè§„åˆ’äº†",
            "timestamp": "2024-02-15T14:01:00",
            "metadata": {},
        },
        {
            "speaker_id": "user_conv2",
            "user_name": "User",
            "content": "æœ‰ä»€ä¹ˆæ–°çš„æ–¹å‘å—ï¼Ÿ",
            "timestamp": "2024-02-15T14:02:00",
            "metadata": {},
        },
        {
            "speaker_id": "john_conv2",
            "user_name": "John",
            "content": "ç°åœ¨è¿˜åœ¨ç ”ç©¶å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„åè°ƒæœºåˆ¶",
            "timestamp": "2024-02-15T14:03:00",
            "metadata": {},
        },
    ]

    raw_data = RawEventData(
        data_type=DataType.CONVERSATION,
        content=messages,
        source="demo_conversation_evolution",
        temporal_info=TemporalInfo(
            timestamp=datetime.fromisoformat("2024-02-15T14:01:00"), duration=120.0, timezone="UTC"
        ),
        metadata={"conversation_id": "conv2", "participant_count": 2},
    )

    conversation_data = ConversationData(raw_data)

    # Build episode to trigger evolution
    episode = await builder.build_episode(conversation_data, "john_conv2")

    print(f"   âœ… æ¼”å˜æƒ…æ™¯åˆ›å»º: {episode.title}")
    print(f"   å‘ç°çš„è¯­ä¹‰çŸ¥è¯†æ•°é‡: {episode.metadata.custom_fields.get('discovered_semantics', 0)}")

    # Check semantic knowledge
    semantic_results = await unified_retrieval.search_semantic_memories(
        owner_id="john_conv2", query="ç ”ç©¶æ–¹å‘", limit=10
    )

    print(f"   ğŸ“Š æ›´æ–°åçš„è¯­ä¹‰çŸ¥è¯†: {len(semantic_results)} ä¸ªèŠ‚ç‚¹")
    for node in semantic_results:
        if node.version > 1:
            print(f"   ğŸ”„ æ¼”å˜çš„çŸ¥è¯†: {node.key} -> {node.value} (ç‰ˆæœ¬ {node.version})")
            print(f"      å†å²å€¼: {node.evolution_history}")


async def test_semantic_discovery():
    """Test semantic knowledge discovery."""
    print("ğŸ”¬ Testing Semantic Discovery...")

    # Setup
    mock_llm = MockLLMProvider()
    discovery_engine = ContextAwareSemanticDiscoveryEngine(mock_llm)

    # Create a test episode
    episode = Episode(
        owner_id="test_user",
        title="Johnè®¨è®ºç ”ç©¶æ–¹å‘",
        content="Johnè¡¨ç¤ºæœ€è¿‘åœ¨ç ”ç©¶AI Agentçš„è¡Œä¸ºè§„åˆ’ï¼Œç‰¹åˆ«å…³æ³¨å†³ç­–æœºåˆ¶ã€‚",
        summary="Johnçš„ç ”ç©¶é‡ç‚¹è½¬å‘AI Agentè¡Œä¸ºè§„åˆ’",
        episode_type=EpisodeType.CONVERSATIONAL,
        level=EpisodeLevel.ATOMIC,
    )

    # Original conversation content
    original_content = """
    [2024-01-15 10:00] User: Johnï¼Œä½ æœ€è¿‘åœ¨ç ”ç©¶ä»€ä¹ˆï¼Ÿ
    [2024-01-15 10:01] John: æˆ‘æœ€è¿‘åœ¨ç ”ç©¶AI Agentçš„è¡Œä¸ºè§„åˆ’
    [2024-01-15 10:02] User: è¿™ä¸ªæ–¹å‘å¾ˆæœ‰å‰æ™¯
    [2024-01-15 10:03] John: æ˜¯çš„ï¼Œç‰¹åˆ«æ˜¯å†³ç­–æœºåˆ¶è¿™å—å¾ˆæœ‰æŒ‘æˆ˜æ€§
    """

    # Discover semantic knowledge
    discovered_nodes = await discovery_engine.discover_semantic_knowledge(episode, original_content)

    print(f"âœ… Discovered {len(discovered_nodes)} semantic nodes:")
    for node in discovered_nodes:
        print(f"   - {node.key}: {node.value}")
        print(f"     Context: {node.context}")
        print(f"     Confidence: {node.confidence}")

    return discovered_nodes


async def run_complete_demo():
    """Run the complete semantic memory demo."""
    print("ğŸ¯ é€‰æ‹©æ¼”ç¤ºæ¨¡å¼ | Select Demo Mode:")
    print("1. å®Œæ•´ç«¯åˆ°ç«¯æ¼”ç¤º (æ¨è)")
    print("2. åŸºç¡€è¯­ä¹‰å‘ç°æµ‹è¯•")

    choice = input("è¯·é€‰æ‹© (1-2) [é»˜è®¤: 1]: ").strip() or "1"

    if choice == "1":
        await test_end_to_end_semantic_memory()
    elif choice == "2":
        await test_semantic_discovery()
    else:
        print("æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œé»˜è®¤æ¼”ç¤º...")
        await test_end_to_end_semantic_memory()


if __name__ == "__main__":
    asyncio.run(run_complete_demo())
