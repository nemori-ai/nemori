import asyncio
import os
from pathlib import Path
import shutil
from datetime import datetime

from dotenv import load_dotenv

# --- Nemori æ ¸å¿ƒç»„ä»¶å¯¼å…¥ ---
from nemori.builders.conversation_builder import ConversationEpisodeBuilder
from nemori.core.builders import EpisodeBuilderRegistry
from nemori.core.data_types import DataType, RawEventData, TemporalInfo
from nemori.episode_manager import EpisodeManager
from nemori.llm.providers.openai_provider import OpenAIProvider
from nemori.retrieval import (
    RetrievalConfig,
    RetrievalQuery,
    RetrievalService,
    RetrievalStorageType,
    RetrievalStrategy,
)

# [æ–°å¢] å¯¼å…¥ DuckDBRawDataRepository
from nemori.storage.duckdb_storage import (
    DuckDBEpisodicMemoryRepository,
    DuckDBRawDataRepository,
)
from nemori.storage.storage_types import StorageConfig

# --- 1. å®šä¹‰ä¸­æ–‡å¯¹è¯æ ·ä¾‹æ•°æ® (ä¸ä¹‹å‰ç›¸åŒ) ---
sample_conversation = [
    {"speaker": "å°æ˜", "text": "ä½ å¥½å•Šï¼Œå°çº¢ï¼æœ€è¿‘åœ¨å¿™ä»€ä¹ˆï¼Ÿ", "timestamp": "2024-05-20T10:00:00Z"},
    {
        "speaker": "å°çº¢",
        "text": "æˆ‘æœ€è¿‘åœ¨å‡†å¤‡å»åŒ—äº¬æ—…æ¸¸ï¼Œæ­£åœ¨çœ‹æ”»ç•¥å‘¢ã€‚æ•…å®«å’Œé•¿åŸæ˜¯å¿…å»çš„ï¼",
        "timestamp": "2024-05-20T10:00:30Z",
    },
    {
        "speaker": "å°æ˜",
        "text": "å¬èµ·æ¥ä¸é”™ï¼åŒ—äº¬çƒ¤é¸­ä¹Ÿä¸€å®šè¦å°å°ã€‚ä½ æ‰“ç®—ä»€ä¹ˆæ—¶å€™å»ï¼Ÿ",
        "timestamp": "2024-05-20T10:01:00Z",
    },
    {
        "speaker": "å°çº¢",
        "text": "è®¡åˆ’ä¸‹ä¸ªæœˆï¼Œå¤§æ¦‚6æœˆ15å·å·¦å³å‡ºå‘ã€‚å¸Œæœ›èƒ½è®¢åˆ°åˆé€‚çš„æœºç¥¨å’Œé…’åº—ã€‚",
        "timestamp": "2024-05-20T10:01:30Z",
    },
]


# --- 2. è¾…åŠ©å‡½æ•°ï¼šè®¾ç½® Nemori æ ¸å¿ƒç»„ä»¶ ---
async def setup_nemori_components(db_dir: Path, llm_provider: OpenAIProvider):
    """ä¸€ä¸ªç‹¬ç«‹çš„å‡½æ•°ï¼Œç”¨äºåˆå§‹åŒ–æ‰€æœ‰ Nemori æœåŠ¡"""
    print("\nğŸ—„ï¸ æ­£åœ¨è®¾ç½®å­˜å‚¨å’Œæ£€ç´¢æœåŠ¡...")

    if db_dir.exists():
        shutil.rmtree(db_dir)
        print(f"ğŸ§¹ å·²æ¸…ç†æ—§çš„æ•°æ®åº“ç›®å½•: {db_dir}")
    db_dir.mkdir(parents=True, exist_ok=True)

    db_path = db_dir / "memory_example.duckdb"

    storage_config = StorageConfig(
        backend_type="duckdb",
        connection_string=str(db_path),
    )

    # [æ–°å¢] åˆå§‹åŒ–åŸå§‹æ•°æ®ä»“åº“
    raw_data_repo = DuckDBRawDataRepository(storage_config)
    await raw_data_repo.initialize()
    print("âœ… åŸå§‹æ•°æ®ä»“åº“ (RawDataRepository) å·²åˆå§‹åŒ–")

    # åˆå§‹åŒ–æƒ…èŠ‚è®°å¿†ä»“åº“
    episode_repo = DuckDBEpisodicMemoryRepository(storage_config)
    await episode_repo.initialize()
    print(f"âœ… DuckDB æƒ…èŠ‚å­˜å‚¨å·²åˆå§‹åŒ–: {db_path}")

    # è®¾ç½®æ£€ç´¢æœåŠ¡ (ä¸ä¹‹å‰ç›¸åŒ)
    retrieval_service = RetrievalService(episode_repo)
    retrieval_config = RetrievalConfig(
        storage_type=RetrievalStorageType.DISK,
        storage_config={"directory": str(db_dir)},
    )
    retrieval_service.register_provider(RetrievalStrategy.BM25, retrieval_config)
    await retrieval_service.initialize()
    print("âœ… BM25 æ£€ç´¢æœåŠ¡å·²é…ç½®")

    # è®¾ç½®æƒ…èŠ‚æ„å»ºå™¨ (ä¸ä¹‹å‰ç›¸åŒ)
    builder_registry = EpisodeBuilderRegistry()
    conversation_builder = ConversationEpisodeBuilder(llm_provider=llm_provider)
    builder_registry.register(conversation_builder)

    # [ä¿®æ”¹] å°† raw_data_repo å®ä¾‹ä¼ é€’ç»™ EpisodeManager
    episode_manager = EpisodeManager(
        raw_data_repo=raw_data_repo,
        episode_repo=episode_repo,
        builder_registry=builder_registry,
        retrieval_service=retrieval_service,
    )
    print("âœ… æƒ…èŠ‚ç®¡ç†å™¨å·²åˆå§‹åŒ– (åŒ…å«åŸå§‹æ•°æ®å­˜å‚¨åŠŸèƒ½)")

    # [ä¿®æ”¹] è¿”å›æ‰€æœ‰éœ€è¦çš„ç»„ä»¶
    return episode_manager, retrieval_service, episode_repo, raw_data_repo


# --- 3. è¾…åŠ©å‡½æ•°ï¼šå°†æ ·ä¾‹æ•°æ®è½¬æ¢ä¸º Nemori æ ¼å¼ (ä¸ä¹‹å‰ç›¸åŒ) ---
def convert_to_raw_event_data(conversation: list, conversation_id: str) -> RawEventData:
    messages = []
    for msg in conversation:
        speaker_name = msg["speaker"]
        speaker_id = f"{'xiaoming' if speaker_name == 'å°æ˜' else 'xiaohong'}_{conversation_id}"

        # [!!!] åœ¨è¿™é‡Œå°±å¤„ç†å¥½æ—¶é—´æˆ³å­—ç¬¦ä¸² [!!!]
        # å°† 'Z' æ›¿æ¢ä¸º '+00:00'ï¼Œä»¥å…¼å®¹ Python 3.10
        iso_timestamp = msg["timestamp"].replace("Z", "+00:00")

        messages.append(
            {
                "speaker_id": speaker_id,
                "user_name": speaker_name,
                "content": msg["text"],
                # ä½¿ç”¨å¤„ç†åçš„æ—¶é—´æˆ³
                "timestamp": iso_timestamp,
            }
        )

    # ç°åœ¨è¿™é‡Œçš„ fromisoformat ä¹Ÿä¼šæ­£ç¡®å·¥ä½œï¼Œå› ä¸º messages é‡Œçš„ timestamp å·²ç»ä¿®å¤äº†
    first_timestamp = datetime.fromisoformat(messages[0]["timestamp"])
    # x = messages[0]["timestamp"]
    # print(f"{type(x)},{x} datetime.fromisoformat-> {type(first_timestamp)},{first_timestamp}")
    last_timestamp = datetime.fromisoformat(messages[-1]["timestamp"])
    # x = messages[-1]["timestamp"]
    # print(f"{type(x)},{x} datetime.fromisoformat-> {type(last_timestamp)},{last_timestamp}")
    duration = (last_timestamp - first_timestamp).total_seconds()
    # print(f"duration, {duration}")
    return RawEventData(
        data_type=DataType.CONVERSATION,
        content=messages,
        source="example_script_with_raw_data",
        temporal_info=TemporalInfo(timestamp=first_timestamp, duration=duration, timezone="UTC"),
        metadata={"conversation_id": conversation_id},
    )


async def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    load_dotenv()
    print("ğŸš€ å¼€å§‹ Nemori å‚¨å­˜ä¸æ£€ç´¢ç¤ºä¾‹ (åŒ…å«åŸå§‹æ•°æ®å­˜å‚¨)")
    print("=" * 50)

    DB_DIR = Path("nemori_example_storage")

    # --- æ­¥éª¤ 1: è®¾ç½® LLM æä¾›è€… (ä¸ä¹‹å‰ç›¸åŒ) ---
    print("\nğŸ¤– æ­£åœ¨è®¾ç½® LLM Provider...")
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° OPENAI_API_KEY ç¯å¢ƒå˜é‡ã€‚")
        return
    llm_provider = OpenAIProvider(model="gpt-4o-mini", temperature=0.1)
    if not await llm_provider.test_connection():
        print("âŒ OpenAI è¿æ¥å¤±è´¥!")
        return
    print(f"âœ… OpenAI è¿æ¥æˆåŠŸ! æ¨¡å‹: {llm_provider.model}")

    # --- æ­¥éª¤ 2: è®¾ç½®å­˜å‚¨ã€æ£€ç´¢å’Œæƒ…èŠ‚ç®¡ç†å™¨ ---
    # [ä¿®æ”¹] æ¥æ”¶æ–°å¢çš„ raw_data_repo
    episode_manager, retrieval_service, episode_repo, raw_data_repo = await setup_nemori_components(
        DB_DIR, llm_provider
    )

    # --- æ­¥éª¤ 3: è½¬æ¢å¹¶å¤„ç†æ•°æ®ä»¥æ„å»ºæƒ…èŠ‚ ---
    print("\nğŸ—ï¸ æ­£åœ¨æ„å»ºæƒ…èŠ‚è®°å¿† (å¹¶è‡ªåŠ¨å­˜å‚¨åŸå§‹æ•°æ®)...")
    conversation_id = "conv_beijing_trip"
    raw_data_to_ingest = convert_to_raw_event_data(sample_conversation, conversation_id)

    owner_ids = {"xiaoming_conv_beijing_trip", "xiaohong_conv_beijing_trip"}
    created_episodes = []
    for owner_id in owner_ids:
        print(f"   ä¸ºæ‰€æœ‰è€… '{owner_id}' å¤„ç†æ•°æ®...")
        # process_raw_data å¯èƒ½è¿”å›ä¸€ä¸ª Episode å¯¹è±¡æˆ– None
        episode = await episode_manager.process_raw_data_to_episode(raw_data_to_ingest, owner_id=owner_id)

        # æ£€æŸ¥è¿”å›çš„æ˜¯å¦æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ Episode å¯¹è±¡
        # if episode:
        # ä½¿ç”¨ .append() å°†å•ä¸ª Episode å¯¹è±¡æ·»åŠ åˆ°åˆ—è¡¨ä¸­
        created_episodes.append(episode)
        # ç›¸åº”çš„ï¼Œæ‰“å°è¯­å¥ä¹Ÿè¦ä¿®æ”¹ï¼Œå› ä¸ºæˆ‘ä»¬ä¸€æ¬¡åªå¤„ç†ä¸€ä¸ªæƒ…èŠ‚
        print(f"   âœ… æˆåŠŸä¸º '{owner_id}' åˆ›å»ºå¹¶å­˜å‚¨äº† 1 ä¸ªæƒ…èŠ‚ã€‚")

    print(f"\nğŸ“Š æ€»å…±åˆ›å»ºäº† {len(created_episodes)} ä¸ªæƒ…èŠ‚ã€‚")

    # --- [æ–°å¢] æ­¥éª¤ 4: éªŒè¯åŸå§‹æ•°æ®å·²å­˜å‚¨ ---
    print("\nğŸ” æ­£åœ¨éªŒè¯åŸå§‹æ•°æ®æ˜¯å¦å·²æˆåŠŸå­˜å‚¨...")
    if created_episodes:
        # æ¯ä¸ªæƒ…èŠ‚éƒ½åŒ…å«å…¶æ¥æºçš„åŸå§‹æ•°æ®çš„ ID
        first_episode = created_episodes[0]
        raw_data_id = first_episode.episode_id

        print(f"   ä»ç¬¬ä¸€ä¸ªæƒ…èŠ‚ä¸­è·å–åˆ° raw_data_id: {raw_data_id}")

        # ä½¿ç”¨ ID ä»åŸå§‹æ•°æ®ä»“åº“ä¸­å–å›æ•°æ®
        retrieved_raw_data = await raw_data_repo.get_raw_data(raw_data_id)

        if retrieved_raw_data:
            print("   âœ… éªŒè¯æˆåŠŸï¼å·²ä»æ•°æ®åº“ä¸­å–å›åŸå§‹æ•°æ®ã€‚")
            print(f"      - æ•°æ®æ¥æº (Source): {retrieved_raw_data.source}")
            print(f"      - æ¶ˆæ¯æ•°é‡ (Message count): {len(retrieved_raw_data.content)}")
        else:
            print("   âŒ éªŒè¯å¤±è´¥ï¼æœªèƒ½å–å›åŸå§‹æ•°æ®ã€‚")
    else:
        print("   âš ï¸ æœªåˆ›å»ºä»»ä½•æƒ…èŠ‚ï¼Œæ— æ³•è¿›è¡ŒéªŒè¯ã€‚")

    # --- æ­¥éª¤ 5: æ„å»º BM25 æ£€ç´¢å¼•ç´¢ (ä¸ä¹‹å‰ç›¸åŒ) ---
    print("\nğŸ”§ æ­£åœ¨æ„å»º BM25 æ£€ç´¢å¼•ç´¢...")
    for owner_id in owner_ids:
        dummy_query = RetrievalQuery(text=".", owner_id=owner_id, limit=1, strategy=RetrievalStrategy.BM25)
        await retrieval_service.search(dummy_query)
        print(f"   âœ… å·²ä¸ºæ‰€æœ‰è€… '{owner_id}' è§¦å‘ç´¢å¼•æ„å»ºã€‚")
    print("âœ… æ£€ç´¢å¼•ç´¢æ„å»ºå®Œæˆã€‚")

    # --- æ­¥éª¤ 6: æ‰§è¡Œæ£€ç´¢æŸ¥è¯¢ (ä¸ä¹‹å‰ç›¸åŒ) ---
    print("\nğŸ” æ­£åœ¨æ‰§è¡Œæ£€ç´¢æŸ¥è¯¢...")
    query_text = "å°çº¢å»åŒ—äº¬æ—…æ¸¸çš„è®¡åˆ’æ˜¯ä»€ä¹ˆï¼Ÿ"
    query_owner_id = "xiaohong_conv_beijing_trip"
    retrieval_query = RetrievalQuery(text=query_text, owner_id=query_owner_id, limit=5, strategy=RetrievalStrategy.BM25)
    search_results = await retrieval_service.search(retrieval_query)

    print(f"\n--- æ£€ç´¢ç»“æœ for query: '{query_text}' (æ‰€æœ‰è€…: {query_owner_id}) ---")
    if search_results.episodes:
        for i, episode in enumerate(search_results.episodes):
            print(f"\n[ç»“æœ {i+1}] (åˆ†æ•°: {episode.score:.4f})")
            print(f"  - æ‘˜è¦: {episode.summary}")
    else:
        print("   æœªæ‰¾åˆ°ç›¸å…³è®°å¿†ã€‚")
    print("----------------------------------------------------------")

    # --- æ­¥éª¤ 7: æ¸…ç†èµ„æº ---
    print("\nğŸ§¹ æ­£åœ¨æ¸…ç†èµ„æº...")
    await retrieval_service.close()
    await episode_repo.close()
    await raw_data_repo.close()  # [æ–°å¢] å…³é—­åŸå§‹æ•°æ®ä»“åº“è¿æ¥
    print("âœ… æ¸…ç†å®Œæˆã€‚")


if __name__ == "__main__":
    asyncio.run(main())
