import os
import asyncio
import threading
from flask import Flask, request, jsonify
from dotenv import load_dotenv
import logging

from nemori_eval.experiment import NemoriExperiment, RetrievalStrategy
from nemori_eval.search import get_nemori_unified_client, nemori_unified_search
from nemori.core.data_types import ConversationData, DataType, RawEventData, TemporalInfo
from datetime import datetime

# --- å…¨å±€é…ç½®å’Œåˆå§‹åŒ– ---

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# åˆ›å»º Flask åº”ç”¨
app = Flask(__name__)
# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)


# Nemori æœåŠ¡ç±»ï¼Œç”¨äºå°è£…æ ¸å¿ƒé€»è¾‘
class NemoriService:
    def __init__(self):
        """
        æœåŠ¡åˆå§‹åŒ–ã€‚
        - åˆ›å»ºå¹¶å¯åŠ¨ä¸€ä¸ªç‹¬ç«‹çš„äº‹ä»¶å¾ªç¯çº¿ç¨‹ï¼Œç”¨äºè¿è¡Œæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡ã€‚
        - åˆå§‹åŒ–ç”¨äºç¼“å­˜ Experiment å’Œ Client å®ä¾‹çš„å­—å…¸ã€‚
        """
        self.loop = asyncio.new_event_loop()
        self.thread = threading.Thread(target=self.start_loop, daemon=True)
        self.thread.start()
        # ä½¿ç”¨å­—å…¸æ¥ç¼“å­˜å·²åˆå§‹åŒ–çš„å®ä¾‹ï¼Œé”®ä¸º version å­—ç¬¦ä¸²
        self.experiments = {}
        self.clients = {}
        app.logger.info("NemoriService initialized with caching enabled.")

    def start_loop(self):
        """å¯åŠ¨å¹¶è¿è¡Œå¼‚æ­¥äº‹ä»¶å¾ªç¯"""
        asyncio.set_event_loop(self.loop)
        self.loop.run_forever()

    def run_async(self, coro):
        """åœ¨æœåŠ¡çš„ä¸»äº‹ä»¶å¾ªç¯ä¸­æäº¤å¹¶è¿è¡Œä¸€ä¸ªåç¨‹"""
        return asyncio.run_coroutine_threadsafe(coro, self.loop).result()

    # --- åˆå§‹åŒ–å‡½æ•° ---

    async def initialize_experiment_async(self, version: str, embed_config: dict, llm_config: dict):
        """
        [æ–°å¢] åˆå§‹åŒ–å¹¶ç¼“å­˜ä¸€ä¸ª NemoriExperiment å®ä¾‹ã€‚
        å¦‚æœæŒ‡å®š version çš„å®ä¾‹å·²å­˜åœ¨ï¼Œå®ƒå°†è¢«æ–°çš„å®ä¾‹è¦†ç›–ã€‚
        """
        if version in self.experiments:
            app.logger.warning(f"Re-initializing experiment for version '{version}'.")
        
        app.logger.info(f"Initializing experiment for version '{version}'...")
        experiment = NemoriExperiment(
            version=version,
            episode_mode="speaker",
            retrievalstrategy=RetrievalStrategy.EMBEDDING,
            max_concurrency=1
        )
        
        # è®¾ç½® LLM å’Œ Embedding
        llm_available = await experiment.setup_llm_provider(**llm_config)
        if not llm_available:
            raise RuntimeError("LLM provider is not available.")
            
        await experiment.setup_storage_and_retrieval(**embed_config)
        
        # ç¼“å­˜å®ä¾‹
        self.experiments[version] = experiment
        app.logger.info(f"Successfully initialized and cached experiment for version '{version}'.")
        return {"status": "success", "message": f"Experiment for version '{version}' initialized."}

    async def initialize_client_async(self, version: str, embed_config: dict):
        """
        [æ–°å¢] åˆå§‹åŒ–å¹¶ç¼“å­˜ä¸€ä¸ª Nemori æœç´¢å®¢æˆ·ç«¯ã€‚
        """
        if version in self.clients:
            app.logger.warning(f"Re-initializing client for version '{version}'.")
            
        app.logger.info(f"Initializing search client for version '{version}'...")
        unified_retrieval, retrieval_service, _, _ = await get_nemori_unified_client(
            version=version,
            retrievalstrategy=RetrievalStrategy.EMBEDDING,
            emb_api_key=embed_config.get("emb_api_key", "EMPTY"),
            emb_base_url=embed_config.get("emb_base_url"),
            embed_model=embed_config.get("embed_model")
        )
        
        # ç¼“å­˜å®¢æˆ·ç«¯å…ƒç»„
        self.clients[version] = (unified_retrieval, retrieval_service)
        app.logger.info(f"Successfully initialized and cached client for version '{version}'.")
        return {"status": "success", "message": f"Client for version '{version}' initialized."}


    # --- æ ¸å¿ƒä¸šåŠ¡é€»è¾‘å‡½æ•° (å·²é‡æ„) ---
    
    def _get_experiment(self, version: str) -> NemoriExperiment:
        """ä»ç¼“å­˜ä¸­è·å– Experiment å®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æŠ›å‡ºå¼‚å¸¸"""
        experiment = self.experiments.get(version)
        if not experiment:
            raise ValueError(f"Experiment for version '{version}' is not initialized. Please call /api/initialize/experiment first.")
        return experiment

    def _get_client(self, version: str) -> tuple:
        """ä»ç¼“å­˜ä¸­è·å– Client å®ä¾‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æŠ›å‡ºå¼‚å¸¸"""
        client = self.clients.get(version)
        if not client:
            raise ValueError(f"Client for version '{version}' is not initialized. Please call /api/initialize/client first.")
        return client

    async def update_memory_asyncV2(self, version: str, conversations: list, boundaries: list):
        """å¼‚æ­¥å¤„ç†è®°å¿†æ›´æ–° V2 - ä½¿ç”¨é¢„åˆå§‹åŒ–çš„ experiment"""
        experiment = self._get_experiment(version)
        user_id = conversations["user_id"]
        
        raw_data = experiment.convert_conversation_to_nemori(conversations, user_id)
        speakers = {msg["speaker_id"] for msg in raw_data.content if isinstance(msg, dict) and "speaker_id" in msg}

        print(f"   ğŸ‘¥ Speakers: {list(speakers)}")

        episode_boundaries = boundaries
        all_episodes = []
        all_semantic_nodes = []
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ”¶é›†çš„æ˜¯ä¸€ä¸ªåˆ—è¡¨çš„åˆ—è¡¨
        #all_semantic_nodes_nested = [] 
        for speaker_id in speakers:
            episodes, semantic_nodes = await experiment._build_episodes_semantic_for_speaker(
                raw_data, speaker_id, episode_boundaries
            )
            all_semantic_nodes.extend(semantic_nodes)
            #all_semantic_nodes_nested.append(semantic_nodes)
            all_episodes.extend(episodes)
            speaker_discoveries = len(semantic_nodes) if semantic_nodes else 0
            print(f"   âœ… {speaker_id}: {len(episodes)} episodes, {speaker_discoveries} semantic_discoveries")

        total_discoveries = len(all_semantic_nodes)
        print(f"   ğŸ“Š Total: {len(all_episodes)} episodes, {total_discoveries} semantic_discoveries from {len(speakers)} speakers")
        # 1. è½¬æ¢ Episode å¯¹è±¡åˆ—è¡¨
        episodes_as_dicts = [ep.to_dict() for ep in all_episodes]
        
        # 2. æ‰å¹³åŒ–å¹¶è½¬æ¢åµŒå¥—çš„ SemanticNode å¯¹è±¡åˆ—è¡¨
        #    - `for sublist in all_semantic_nodes_nested` éå†å¤–å±‚åˆ—è¡¨
        #    - `for node in sublist` éå†å†…å±‚åˆ—è¡¨ä¸­çš„æ¯ä¸ª SemanticNode å¯¹è±¡
        #    - `node.to_dict()` å°†æ¯ä¸ªå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
        #    å‡è®¾ SemanticNode ç±»ä¹Ÿæœ‰ä¸€ä¸ª .to_dict() æ–¹æ³•

        nodes_as_dicts = [
            node.to_dict() 
            for sublist in all_semantic_nodes
            for node in sublist
        ]
        return {
            "status": "completed",
            "user_id": user_id,
            "episodes": episodes_as_dicts,
            "semantic_nodes": nodes_as_dicts
        }

    async def detect_boundaries_async(self, version: str, conversations: list):
        """å¼‚æ­¥å¤„ç†è¾¹ç•Œæ£€æµ‹ - ä½¿ç”¨é¢„åˆå§‹åŒ–çš„ experiment"""
        experiment = self._get_experiment(version)
        
        raw_data = experiment.convert_conversation_to_nemori(conversations, conversations["user_id"])
        conversation_data = ConversationData(raw_data)
        episode_boundaries = await experiment._detect_conversation_boundaries(conversation_data.messages)
        
        return {
            "status": "completed",
            "episode_boundaries": episode_boundaries
        }

    async def update_memory_async(self, version: str, conversations: list):
        """å¼‚æ­¥å¤„ç†è®°å¿†æ›´æ–° - ä½¿ç”¨é¢„åˆå§‹åŒ–çš„ experiment"""
        experiment = self._get_experiment(version)
        
        experiment.conversations = conversations
        app.logger.info(f"[{version}] Loaded {len(conversations)} conversations for memory update.")

        await experiment.build_episodes_semantic()
        app.logger.info(f"[{version}] Memory update complete. Created {len(experiment.episodes)} episodes.")
        
        return {
            "status": "completed", 
            "episodes_created": len(experiment.episodes),
            "semantic_concepts": getattr(experiment, 'actual_semantic_count', 0)
        }

    async def query_memory_async(self, version: str, user_id: str, query: str, speaker_a: str, speaker_b: str, top_k: int):
        """å¼‚æ­¥å¤„ç†è®°å¿†æŸ¥è¯¢ - ä½¿ç”¨é¢„åˆå§‹åŒ–çš„ client"""
        client = self._get_client(version)
        
        speaker_a_user_id = f"{speaker_a.lower().replace(' ', '_')}_{user_id}"
        speaker_b_user_id = f"{speaker_b.lower().replace(' ', '_')}_{user_id}"
        
        app.logger.info(f"[{version}] Performing search for query: '{query}'")
        context, duration_ms = await nemori_unified_search(
            unified_retrieval_service=client[0],
            retrieval_service=client[1],
            query=query,
            speaker_a_user_id=speaker_a_user_id,
            speaker_b_user_id=speaker_b_user_id,
            top_k=top_k
        )
        return context, duration_ms

# å®ä¾‹åŒ–æœåŠ¡
nemori_service = NemoriService()

# --- API è·¯ç”±å®šä¹‰ ---

# --- [æ–°å¢] åˆå§‹åŒ–è·¯ç”± ---
@app.route('/api/initialize/experiment', methods=['POST'])
def initialize_experiment():
    """åˆå§‹åŒ–å¹¶ç¼“å­˜ä¸€ä¸ª Experiment å®ä¾‹"""
    data = request.json
    version = data['version']
    llm_config = data['llm_config']
    embed_config = data['embed_config']
    
    result = nemori_service.run_async(
        nemori_service.initialize_experiment_async(version, embed_config, llm_config)
    )
    return jsonify(result), 200


@app.route('/api/initialize/client', methods=['POST'])
def initialize_client():
    """åˆå§‹åŒ–å¹¶ç¼“å­˜ä¸€ä¸ªæœç´¢å®¢æˆ·ç«¯å®ä¾‹"""
    data = request.json
    version = data['version']
    embed_config = data['embed_config']
    
    result = nemori_service.run_async(
        nemori_service.initialize_client_async(version, embed_config)
    )
    return jsonify(result), 200



# --- ä¸šåŠ¡é€»è¾‘è·¯ç”± (å·²ä¿®æ”¹) ---

@app.route('/api/boundaries/detect', methods=['POST'])
def detect_boundaries():
    """æ£€æµ‹å¯¹è¯è¾¹ç•Œ"""
    data = request.json
    version = data['version']
    messages = data['messages']
    result = nemori_service.run_async(
        nemori_service.detect_boundaries_async(version, messages)
    )
    return jsonify(result), 200


@app.route('/api/memory/update-v2', methods=['POST'])
def update_memory_v2():
    """ä½¿ç”¨é¢„åˆ†å‰²çš„æ¶ˆæ¯ç›´æ¥æ›´æ–°è®°å¿†åº“"""
    data = request.json
    version = data['version']
    messages = data['messages']
    boundaries = data['boundaries']
    result = nemori_service.run_async(
        nemori_service.update_memory_asyncV2(version, messages, boundaries)
    )
    return jsonify(result), 200



@app.route('/api/memory/update', methods=['POST'])
def update_memory():
    """æ¥æ”¶å¯¹è¯æ•°æ®ï¼Œæ›´æ–°è®°å¿†åº“"""
    data = request.json
    version = data['version']
    conversations = data['conversations']
    
    # æ£€æŸ¥ experiment æ˜¯å¦å·²åˆå§‹åŒ– (åœ¨åŒæ­¥ä»£ç ä¸­)
    nemori_service._get_experiment(version)

    # æäº¤åˆ°åå°æ‰§è¡Œ
    asyncio.run_coroutine_threadsafe(
        nemori_service.update_memory_async(version, conversations),
        nemori_service.loop
    )
    return jsonify({
        "status": "success",
        "message": "Memory update process started successfully.",
        "version": version
    }), 202
  


@app.route('/api/memory/query', methods=['POST'])
def query_memory():
    """æŸ¥è¯¢è®°å¿†åº“"""
    data = request.json
    version = data['version']
    # ... (å…¶ä½™å‚æ•°)
    context, duration_ms = nemori_service.run_async(
        nemori_service.query_memory_async(
            version, data['user_id'], data['query'], 
            data['speaker_a'], data['speaker_b'], data.get('top_k', 20)
        )
    )
    return jsonify({
        "status": "success",
        "query": data['query'],
        "context": context,
        "duration_ms": duration_ms
    }), 200



@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({"status": "ok"}), 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5001, debug=False)