#!/usr/bin/env python3
"""
Nemori ç®€åŒ–åŠŸèƒ½æµ‹è¯•è„šæœ¬

è¿™æ˜¯ä¸€ä¸ªæ›´ç®€å•æ˜“ç”¨çš„æµ‹è¯•è„šæœ¬ï¼Œæµ‹è¯•nemoriçš„æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åˆ›å»ºç®€å•ä½†ä¸°å¯Œçš„å¯¹è¯æ•°æ®
2. æµ‹è¯•episodic memoryçš„åˆ›å»ºå’Œå­˜å‚¨
3. éªŒè¯semantic memoryçš„çŸ¥è¯†å‘ç°
4. æ¼”ç¤ºunified retrievalçš„æœç´¢èƒ½åŠ›

ä½¿ç”¨æ–¹æ³•:
python simple_nemori_full_test.py
"""

import asyncio
import pandas as pd
from datetime import datetime
from pathlib import Path
import sys

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥nemoriæ¨¡å—
current_dir = Path(__file__).parent
nemori_root = current_dir / "nemori"
sys.path.insert(0, str(nemori_root))
sys.path.insert(0, str(current_dir / "evaluation/memos/evaluation/scripts/locomo"))

from nemori_eval.experiment import NemoriExperiment, RetrievalStrategy
from nemori.retrieval import RetrievalQuery


def create_simple_test_conversations():
    """åˆ›å»ºç®€å•çš„æµ‹è¯•å¯¹è¯æ•°æ®"""
    conversations = [
        {
            "user_id": "conv_001",
            "conversation": {
                "speaker_a": "Alice",
                "speaker_b": "Bob",
                "session_1": [
                    {
                        "speaker": "Alice",
                        "text": "æˆ‘æœ€è¿‘åœ¨å­¦ä¹ Pythonæœºå™¨å­¦ä¹ ï¼Œä½ æœ‰ä»€ä¹ˆå»ºè®®çš„åº“å—ï¼Ÿ",
                        "timestamp": "2024-01-20T10:00:00Z"
                    },
                    {
                        "speaker": "Bob",
                        "text": "æ¨èscikit-learnä½œä¸ºå…¥é—¨ï¼Œpandasç”¨äºæ•°æ®å¤„ç†ï¼Œnumpyç”¨äºæ•°å€¼è®¡ç®—ã€‚",
                        "timestamp": "2024-01-20T10:02:00Z"
                    },
                    {
                        "speaker": "Alice",
                        "text": "æ·±åº¦å­¦ä¹ æ–¹é¢å‘¢ï¼Ÿæˆ‘å¬è¯´TensorFlowå’ŒPyTorchå¾ˆæµè¡Œã€‚",
                        "timestamp": "2024-01-20T10:04:00Z"
                    },
                    {
                        "speaker": "Bob",
                        "text": "PyTorchå¯¹åˆå­¦è€…æ›´å‹å¥½ï¼ŒåŠ¨æ€å›¾æœºåˆ¶æ›´å®¹æ˜“è°ƒè¯•ã€‚TensorFlowåœ¨ç”Ÿäº§ç¯å¢ƒåº”ç”¨æ›´å¹¿æ³›ã€‚",
                        "timestamp": "2024-01-20T10:06:00Z"
                    }
                ],
                "session_1_date_time": "10:00 AM on 20 January, 2024"
            }
        },
        {
            "user_id": "conv_002", 
            "conversation": {
                "speaker_a": "Charlie",
                "speaker_b": "Diana",
                "session_1": [
                    {
                        "speaker": "Charlie",
                        "text": "æˆ‘ä»¬å…¬å¸è¦å¼€å‘ä¸€ä¸ªæ¨èç³»ç»Ÿï¼Œä½ è§‰å¾—ç”¨ä»€ä¹ˆç®—æ³•æ¯”è¾ƒå¥½ï¼Ÿ",
                        "timestamp": "2024-01-21T14:00:00Z"
                    },
                    {
                        "speaker": "Diana",
                        "text": "ååŒè¿‡æ»¤æ˜¯ç»å…¸é€‰æ‹©ï¼Œä½†ç°åœ¨æ·±åº¦å­¦ä¹ çš„embeddingæ–¹æ³•æ•ˆæœæ›´å¥½ã€‚",
                        "timestamp": "2024-01-21T14:02:00Z"
                    },
                    {
                        "speaker": "Charlie",
                        "text": "å†·å¯åŠ¨é—®é¢˜æ€ä¹ˆè§£å†³ï¼Ÿæ–°ç”¨æˆ·æ²¡æœ‰å†å²æ•°æ®ã€‚",
                        "timestamp": "2024-01-21T14:04:00Z"
                    },
                    {
                        "speaker": "Diana",
                        "text": "å¯ä»¥ç»“åˆå†…å®¹è¿‡æ»¤ï¼ŒåŸºäºç‰©å“ç‰¹å¾æ¨èã€‚æˆ–è€…ç”¨æµè¡Œåº¦ä½œä¸ºfallbackç­–ç•¥ã€‚",
                        "timestamp": "2024-01-21T14:06:00Z"
                    }
                ],
                "session_1_date_time": "2:00 PM on 21 January, 2024"
            }
        },
        {
            "user_id": "conv_003",
            "conversation": {
                "speaker_a": "Eve", 
                "speaker_b": "Frank",
                "session_1": [
                    {
                        "speaker": "Eve",
                        "text": "å‘¨æœ«æƒ³å»æˆ·å¤–æ´»åŠ¨ï¼Œä½ æœ‰ä»€ä¹ˆæ¨èå—ï¼Ÿ",
                        "timestamp": "2024-01-22T16:00:00Z"
                    },
                    {
                        "speaker": "Frank",
                        "text": "å¯ä»¥å»çˆ¬å±±ï¼Œæˆ‘çŸ¥é“ä¸€ä¸ªåœ°æ–¹é£æ™¯å¾ˆå¥½ï¼Œè€Œä¸”ä¸å¤ªéš¾çˆ¬ã€‚",
                        "timestamp": "2024-01-22T16:02:00Z"
                    },
                    {
                        "speaker": "Eve",
                        "text": "å¬èµ·æ¥ä¸é”™ï¼æˆ‘å–œæ¬¢æ‹ç…§ï¼Œé‚£é‡Œé€‚åˆæ‘„å½±å—ï¼Ÿ",
                        "timestamp": "2024-01-22T16:04:00Z"
                    },
                    {
                        "speaker": "Frank",
                        "text": "ç»å¯¹é€‚åˆï¼å±±é¡¶å¯ä»¥çœ‹æ—¥å‡ºï¼Œè¿˜æœ‰ç€‘å¸ƒå’Œæ£®æ—ï¼Œæˆ‘ç»å¸¸å¸¦ç›¸æœºå»ã€‚",
                        "timestamp": "2024-01-22T16:06:00Z"
                    }
                ],
                "session_1_date_time": "4:00 PM on 22 January, 2024"
            }
        }
    ]
    
    return pd.DataFrame(conversations)


async def simple_test():
    """è¿è¡Œç®€åŒ–çš„æµ‹è¯•æµç¨‹"""
    print("ğŸš€ Nemori ç®€åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    print("ğŸ“‹ åˆ›å»ºæµ‹è¯•æ•°æ®...")
    test_data = create_simple_test_conversations()
    print(f"âœ… åˆ›å»ºäº† {len(test_data)} ä¸ªå¯¹è¯")
    
    # åˆå§‹åŒ–å®éªŒ
    print("\nğŸ”§ åˆå§‹åŒ– Nemori...")
    experiment = NemoriExperiment(
        version="simple_test",
        episode_mode="speaker",
        retrievalstrategy=RetrievalStrategy.EMBEDDING,
        max_concurrency=1
    )
    
    try:
        # è®¾ç½®LLM (ä½¿ç”¨ç®€å•é…ç½®)
        print("\nğŸ¤– è®¾ç½® LLM...")
        api_key = "sk-NuO4dbNTkXXi5zWYkLFnhyug1kkqjeysvrb74pA9jTGfz8cm"
        base_url = "https://jeniya.cn/v1"
        model = "gpt-4o-mini"
        
        llm_ok = await experiment.setup_llm_provider(model, api_key, base_url)
        if not llm_ok:
            print("âŒ LLM è®¾ç½®å¤±è´¥")
            return
            
        # åŠ è½½æ•°æ®
        print("\nğŸ“Š åŠ è½½æ•°æ®...")
        experiment.load_locomo_data(test_data)
        
        # è®¾ç½®å­˜å‚¨å’Œæ£€ç´¢
        print("\nğŸ—„ï¸ è®¾ç½®å­˜å‚¨...")
        await experiment.setup_storage_and_retrieval(
            emb_api_key="EMPTY",
            emb_base_url="http://localhost:6007/v1",
            embed_model="qwen3-emb"
        )
        
        # æ„å»ºepisodeså’Œè¯­ä¹‰è®°å¿†
        print("\nğŸ—ï¸ æ„å»ºè®°å¿†...")
        await experiment.build_episodes_semantic()
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“Š ç»“æœç»Ÿè®¡:")
        print(f"  Episodes: {len(experiment.episodes)}")
        semantic_count = getattr(experiment, 'actual_semantic_count', 0)
        print(f"  è¯­ä¹‰æ¦‚å¿µ: {semantic_count}")
        
        # ç®€å•çš„æ£€ç´¢æµ‹è¯•
        print(f"\nğŸ” æ£€ç´¢æµ‹è¯•:")
        if experiment.episodes:
            owner_id = experiment.episodes[0].owner_id
            
            test_queries = ["æœºå™¨å­¦ä¹ ", "æ¨èç³»ç»Ÿ", "æ‘„å½±"]
            
            for query_text in test_queries:
                print(f"\n  æŸ¥è¯¢: '{query_text}'")
                try:
                    query = RetrievalQuery(
                        text=query_text,
                        owner_id=owner_id,
                        limit=2,
                        strategy=experiment.retrievalstrategy
                    )
                    
                    results = await experiment.retrieval_service.search(query)
                    
                    if results and results.episodes:
                        print(f"    âœ… æ‰¾åˆ° {len(results.episodes)} ä¸ªç›¸å…³ç»“æœ")
                        for result in results.episodes[:1]:  # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ª
                            content = result.content[:100] + "..." if len(result.content) > 100 else result.content
                            print(f"    ğŸ“„ {content}")
                    else:
                        print(f"    âŒ æœªæ‰¾åˆ°ç»“æœ")
                        
                except Exception as e:
                    print(f"    âŒ æŸ¥è¯¢å‡ºé”™: {e}")
        
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(simple_test())